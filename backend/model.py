# -*- coding: utf-8 -*-
"""Plutus.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W0P6XxR7rxF0cK_5nQ6JbC67QhzO6iY-

### ***Plutus: Your Personal Financial Advising AI***

Plutus is an advanced AI-powered financial advisor designed to help you optimize your money flow and accurately predict your credit score. Leveraging cutting-edge machine learning techniques, Plutus analyzes your financial data to provide personalized insights and recommendations. Whether you're looking to improve your budgeting, manage debt, or understand the factors impacting your credit health, Plutus is here to guide you towards a stronger financial future.

## Phase 1: Credit Risk Score Predictor

In this initial phase, Plutus focuses on building a robust credit risk score predictor. Utilizing fundamental machine learning algorithms such as Logistic Regression and Decision Tree, this module analyzes various financial indicators to assess an individual's creditworthiness. The goal is to provide an accurate prediction of credit risk, empowering users to understand their financial standing and take proactive steps towards improving it.

# Imports, Data Selection and Preprocessing
"""

import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub
from sklearn.tree import plot_tree
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report

path = kagglehub.dataset_download("adilshamim8/credit-risk-benchmark-dataset")
df = pd.read_csv(path+'/Credit Risk Benchmark Dataset.csv')

print("Dataset Shape:", df.shape)
print('Empty Cell :',df.isna().sum().sum())

X = df.drop("dlq_2yrs", axis=1)
y = df["dlq_2yrs"]

X = X.fillna(X.median())

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=32
)

scaler = StandardScaler()



X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""#Logistic Regression Model Training and Evaluation"""

model = LogisticRegression(class_weight='balanced', max_iter=1000)
model.fit(X_train_scaled, y_train)

# y_pred = model.predict(X_test_scaled)
y_prob = model.predict_proba(X_test_scaled)[:, 1]
threshold=0.4
y_pred = (y_prob >= threshold).astype(int)

print("\nModel Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_prob))

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.savefig("confusion_matrix.png", dpi=300, bbox_inches='tight')

plt.show()

fpr, tpr, _ = roc_curve(y_test, y_prob)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr)
plt.plot([0,1], [0,1], linestyle='--')
plt.title("ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.savefig("roc_curve.png", dpi=300, bbox_inches='tight')
plt.show()

plt.figure(figsize=(6,4))
sns.histplot(y_prob, bins=50)
plt.title("Predicted Default Probability Distribution")
plt.xlabel("Probability")
plt.ylabel("Count")
plt.savefig("Predicted Default Probability Distribution.png", dpi=300, bbox_inches='tight')

plt.show()

coefficients = pd.DataFrame({
    "Feature": X.columns,
    "Coefficient": model.coef_[0]
}).sort_values(by="Coefficient", ascending=False)

print("\nTop Risk Factors:")
print(coefficients)

plt.figure(figsize=(8,10))
coefficients.sort_values("Coefficient").plot(
    x="Feature",
    y="Coefficient",
    kind="barh",
    legend=False
)
plt.title("Logistic Regression Feature Importance")
plt.tight_layout()
plt.savefig("Logistic Regression Feature Importance.png", dpi=300, bbox_inches='tight')

plt.show()

"""#Decision Tree Model Training and Evaluation"""

model2=DecisionTreeClassifier(max_depth=3)
model2.fit(X_train_scaled, y_train)

y_pred_2 = model2.predict(X_test_scaled)
y_prob_2 = model2.predict_proba(X_test_scaled)[:, 1]

print("\nModel Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_2))
print("Precision:", precision_score(y_test, y_pred_2))
print("Recall:", recall_score(y_test, y_pred_2))
print("ROC-AUC:", roc_auc_score(y_test, y_prob_2))

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred_2))

plt.figure(figsize=(40,20))

plot_tree(
    model2,
    feature_names=X.columns,
    class_names=["No Default", "Default"],
    filled=True,
    rounded=True,
    fontsize=10,
    proportion=True
)

plt.title("Decision Tree Structure (Credit Risk Model)")
plt.show()

importances = pd.DataFrame({
    "Feature": X.columns,
    "Importance": model2.feature_importances_
}).sort_values(by="Importance", ascending=False)

plt.figure(figsize=(8,6))
importances.plot(
    x="Feature",
    y="Importance",
    kind="barh",
    legend=False
)

plt.title("Decision Tree Feature Importance")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

joblib.dump(model, 'logistic_model.pkl')
joblib.dump(model2, 'decision_tree_model.pkl')